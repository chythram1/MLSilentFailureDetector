# ğŸ” ML Silent Failure Detection System

An early warning system that detects machine learning model degradation **before** accuracy drops, giving teams time to investigate and fix issues.
Some Pictures from Streamlit dashboard:

<img width="935" height="317" alt="image" src="https://github.com/user-attachments/assets/850b146c-0d5d-48c5-a70e-21e915d8de02" />
<img width="652" height="353" alt="image" src="https://github.com/user-attachments/assets/957cd510-c465-4478-870e-f4b1086e4b75" />
<img width="658" height="374" alt="image" src="https://github.com/user-attachments/assets/c0f7f2dd-42a3-4ba1-9ada-042cc65386c9" />
<img width="667" height="337" alt="image" src="https://github.com/user-attachments/assets/7c32849d-ade8-4df2-ae5c-7bb23835ec36" />
<img width="593" height="341" alt="image" src="https://github.com/user-attachments/assets/7aacdc95-d648-4d46-97af-cf562218be8f" />

---

## ğŸ¯ The Problem

Machine learning models in production **degrade silently**. By the time you notice accuracy dropped, you've already made thousands of bad predictions.

```
Traditional Monitoring:

Week 1-10:  Model seems fine (no labels yet to verify)
Week 11:    Labels arrive â†’ Accuracy dropped to 60%
Week 12:    Panic. Thousands of wrong predictions already made.
```

**Why does this happen?**

- Customer behavior changes over time
- Economic conditions shift
- Marketing brings in different demographics
- Seasonal patterns emerge

The model was trained on historical data, but production data keeps evolving.

---

## âœ… The Solution

Monitor **input data distributions** instead of waiting for labels. If today's data looks different from training data, the model's predictions are suspectâ€”even before you can prove it.

```
This System:

Week 1-3:   PSI low, model stable
Week 4:     âš ï¸ PSI spikes! Data distribution shifting.
Week 5-10:  Team investigates, retrains model
Week 11:    Crisis averted. Model still accurate.
```

---

## ğŸ“Š Key Results

| Metric | Value |
|--------|-------|
| Drift detected at | Batch 4 |
| Accuracy dropped at | Batch 15 |
| **Early warning** | **11 batches** |
| Accuracy degradation | 80% â†’ 60% |

**The system detected problems 11 time windows before users would have noticed.**

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TRAINING PHASE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Historical Data â†’ Train Model â†’ Save Reference Baseline    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PRODUCTION PHASE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  New Data Batch                                             â”‚
â”‚       â”‚                                                     â”‚
â”‚       â–¼                                                     â”‚
â”‚  Calculate PSI (compare to reference)                       â”‚
â”‚       â”‚                                                     â”‚
â”‚       â–¼                                                     â”‚
â”‚  PSI > 0.25? â”€â”€â”€YESâ”€â”€â”€â†’ ğŸš¨ Alert! Investigate drift        â”‚
â”‚       â”‚                                                     â”‚
â”‚       NO                                                    â”‚
â”‚       â–¼                                                     â”‚
â”‚  Continue monitoring                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
ml-silent-failure/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ credit_default.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ reference_data.csv
â”‚       â”œâ”€â”€ reference_with_labels.csv
â”‚       â”œâ”€â”€ simulated_batches.csv
â”‚       â”œâ”€â”€ psi_results.csv
â”‚       â””â”€â”€ drift_accuracy_results.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_model.pkl
â”‚   â””â”€â”€ scaler.pkl
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ drift_simulator.py
â”‚   â”œâ”€â”€ psi_calculator.py
â”‚   â”œâ”€â”€ batch_evaluator.py
â”‚   â””â”€â”€ dashboard.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ test.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Quick Start

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/ml-silent-failure.git
cd ml-silent-failure
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Download the dataset

Download the [UCI Credit Card Default dataset](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients) and place it in `data/raw/credit_default.csv`.

### 4. Run the pipeline

```bash
# Train baseline model
run the third cell in test.ipynb

# Generate drifted batches
python src/drift_simulator.py

# Calculate PSI scores
python src/psi_calculator.py

# Evaluate accuracy per batch
python src/batch_evaluator.py

# Launch dashboard
python -m streamlit run src/dashboard.py
```

---

## ğŸ“ˆ What is PSI?

**Population Stability Index (PSI)** measures how different two distributions are.

```
Reference (training):   |  â–‚â–„â–†â–ˆâ–†â–„â–‚  |    â† What model learned
Current (production):   |â–‚â–„â–†â–ˆâ–†â–„â–‚    |    â† What model sees now
                              â†‘
                         PSI detects this shift
```

### Interpretation

| PSI Value | Meaning |
|-----------|---------|
| < 0.1 | No significant drift |
| 0.1 - 0.25 | Moderate drift, investigate |
| > 0.25 | Significant drift, model unreliable |

### Why PSI?

- **Label-free**: Works without ground truth
- **Interpretable**: Clear thresholds
- **Industry standard**: Used at banks, insurance, and tech companies

---

## ğŸ”¬ Drift Simulation

We simulate real-world drift by gradually shifting key features:

| Feature | What It Is | Drift Scenario |
|---------|------------|----------------|
| `PAY_0` | Payment status last month (0=on time, 1+=late) | Economic recession â†’ more late payments |
| `BILL_AMT1` | Bill amount last month | Inflation â†’ higher balances |
| `PAY_AMT2` | Payment amount 2 months ago | Customer mix changes |

These features were chosen because they have the **highest model coefficients**â€”drifting them impacts predictions most.

---

## ğŸ–¥ï¸ Dashboard Features

The Streamlit dashboard provides:

- **Accuracy timeline**: Watch model performance over batches
- **PSI monitoring**: Color-coded drift detection (green=stable, red=alert)
- **Feature breakdown**: Which features are drifting most
- **Event timeline**: Clear narrative of when drift was detected vs. when accuracy dropped
- **Recommended actions**: What to do when drift is detected

---

## ğŸ§  Key Concepts Demonstrated

1. **Silent failure in ML**: Models degrade without obvious errors
2. **Distribution monitoring**: Detecting problems without labels
3. **PSI calculation**: Industry-standard drift metric
4. **Feature importance**: Knowing which features matter most
5. **Proactive monitoring**: Early warning systems for ML

---

## ğŸ› ï¸ Tech Stack

- **Python 3.8+**
- **scikit-learn**: Baseline model training
- **pandas/numpy**: Data manipulation
- **Streamlit**: Interactive dashboard
- **Plotly**: Visualizations
- **joblib**: Model serialization

---

## ğŸ“š References

- [UCI Credit Card Default Dataset](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)
- [Understanding UCI Credit Default Dataset](https://medium.com/@manish.kumar_61520/the-default-of-credit-card-clients-dataset-81908562a67eh)
- [Population Stability Index (PSI) Explained](https://www.listendata.com/2015/05/population-stability-index.html)
- [Monitoring ML Models in Production](https://christophergs.com/machine-learning/2020/03/14/how-to-monitor-machine-learning-models/)

---

## ğŸ”® Future Improvements

- [ ] Add more drift metrics (KL Divergence, KS Test)
- [ ] Implement automated retraining pipeline
- [ ] Add email/Slack alerts
- [ ] Support real-time streaming data
- [ ] Add concept drift detection (feature-label relationship changes)
